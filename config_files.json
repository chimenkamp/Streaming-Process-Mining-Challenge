{
  "stream_configuration.json": {
    "streams": [
      {
        "id": "simple_sequential",
        "name": "Simple Concept Drift",
        "description": "A basic stream containing a simple concept drift. The first 60% of the stream follows one model, and the last 40% follows another.\n\nThis stream tests your algorithm's ability to detect sudden changes in process behavior.",
        "type": "pnml_drift",
        "is_testing": true,
        "pnml_log_a": "data/model_one.pnml",
        "pnml_log_b": "data/model_two.pnml",
        "drift_config": {
          "drift_type": "sudden",
          "drift_begin_percentage": 0.6,
          "drift_end_percentage": 0.6,
          "event_level_drift": false,
          "num_cases_a": 300,
          "num_cases_b": 200
        }
      },
      {
        "id": "gradual_drift",
        "name": "Gradual Concept Drift",
        "description": "A stream with gradual concept drift occurring between 30% and 70% of the stream.\n\nThis tests your algorithm's adaptability to slowly changing processes.",
        "type": "pnml_drift",
        "is_testing": true,
        "pnml_log_a": "data/model_one.pnml",
        "pnml_log_b": "data/model_two.pnml",
        "drift_config": {
          "drift_type": "gradual",
          "drift_begin_percentage": 0.3,
          "drift_end_percentage": 0.7,
          "event_level_drift": true,
          "num_cases_a": 250,
          "num_cases_b": 250
        }
      },
      {
        "id": "early_drift",
        "name": "Early Sudden Drift",
        "description": "A stream where concept drift occurs early (at 20% of the stream).\n\nThis challenges algorithms with limited learning time before drift occurs.",
        "type": "pnml_drift",
        "is_testing": true,
        "pnml_log_a": "data/model_one.pnml",
        "pnml_log_b": "data/model_two.pnml",
        "drift_config": {
          "drift_type": "sudden",
          "drift_begin_percentage": 0.2,
          "drift_end_percentage": 0.2,
          "event_level_drift": false,
          "num_cases_a": 150,
          "num_cases_b": 350
        }
      },
      {
        "id": "multiple_drifts",
        "name": "Multiple Concept Drifts",
        "description": "A complex stream with multiple drift points to test advanced adaptation capabilities.\n\nThis is an advanced challenge stream for sophisticated algorithms.",
        "type": "pnml_drift",
        "is_testing": true,
        "pnml_log_a": "data/model_one.pnml",
        "pnml_log_b": "data/model_two.pnml",
        "drift_config": {
          "drift_type": "sudden",
          "drift_begin_percentage": 0.25,
          "drift_end_percentage": 0.25,
          "event_level_drift": false,
          "num_cases_a": 200,
          "num_cases_b": 300,
          "secondary_drift": {
            "drift_begin_percentage": 0.75,
            "drift_end_percentage": 0.75
          }
        }
      }
    ],
    "evaluation_settings": {
      "default_test_cases": [100, 250, 500],
      "timeout_seconds": 300,
      "max_file_size_mb": 50,
      "allowed_extensions": [".py", ".zip"],
      "baseline_threshold": 0.1,
      "error_threshold": 0.3
    },
    "leaderboard_settings": {
      "refresh_interval_seconds": 30,
      "max_entries_displayed": 50,
      "score_weights": {
        "accuracy": 0.30,
        "mae": 0.25,
        "rmse": 0.20,
        "speed": 0.15,
        "robustness": 0.10
      }
    }
  },
  
  "requirements.txt": [
    "dash>=2.14.0",
    "dash-bootstrap-components>=1.5.0",
    "plotly>=5.15.0",
    "pandas>=2.0.0",
    "numpy>=1.24.0",
    "sqlalchemy>=2.0.0",
    "pm4py>=2.7.0",
    "scikit-learn>=1.3.0",
    "python-dateutil>=2.8.0"
  ],
  
  "docker-compose.yml": {
    "version": "3.8",
    "services": {
      "challenge-app": {
        "build": ".",
        "ports": ["8050:8050"],
        "environment": [
          "DASH_ENV=production",
          "DATABASE_URL=sqlite:///data/challenge.db"
        ],
        "volumes": [
          "./data:/app/data",
          "./uploads:/app/uploads"
        ]
      },
      "postgres": {
        "image": "postgres:13",
        "environment": {
          "POSTGRES_DB": "challenge",
          "POSTGRES_USER": "challenge_user",
          "POSTGRES_PASSWORD": "secure_password"
        },
        "volumes": ["postgres_data:/var/lib/postgresql/data"],
        "ports": ["5432:5432"]
      }
    },
    "volumes": {
      "postgres_data": {}
    }
  },
  
  "Dockerfile": [
    "FROM python:3.9-slim",
    "",
    "WORKDIR /app",
    "",
    "# Install system dependencies",
    "RUN apt-get update && apt-get install -y \\",
    "    gcc \\",
    "    && rm -rf /var/lib/apt/lists/*",
    "",
    "# Install Python dependencies",
    "COPY requirements.txt .",
    "RUN pip install --no-cache-dir -r requirements.txt",
    "",
    "# Copy application code",
    "COPY . .",
    "",
    "# Create necessary directories",
    "RUN mkdir -p uploads data assets/config assets/data",
    "",
    "# Set environment variables",
    "ENV PYTHONPATH=/app",
    "ENV DASH_ENV=production",
    "",
    "# Expose port",
    "EXPOSE 8050",
    "",
    "# Health check",
    "HEALTHCHECK --interval=30s --timeout=10s --start-period=5s --retries=3 \\",
    "    CMD curl -f http://localhost:8050/health || exit 1",
    "",
    "# Run the application",
    "CMD [\"python\", \"app.py\"]"
  ],
  
  "nginx.conf": [
    "upstream challenge_app {",
    "    server app:8050;",
    "}",
    "",
    "server {",
    "    listen 80;",
    "    server_name your-domain.com;",
    "",
    "    client_max_body_size 100M;",
    "",
    "    location / {",
    "        proxy_pass http://challenge_app;",
    "        proxy_set_header Host $host;",
    "        proxy_set_header X-Real-IP $remote_addr;",
    "        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;",
    "        proxy_set_header X-Forwarded-Proto $scheme;",
    "        proxy_read_timeout 300s;",
    "        proxy_connect_timeout 75s;",
    "    }",
    "",
    "    location /health {",
    "        proxy_pass http://challenge_app;",
    "        access_log off;",
    "    }",
    "}"
  ],
  
  "environment_setup.sh": [
    "#!/bin/bash",
    "",
    "# Streaming Process Mining Challenge Setup Script",
    "",
    "echo \"🚀 Setting up Streaming Process Mining Challenge Platform...\"",
    "",
    "# Create directory structure",
    "mkdir -p assets/config assets/data src/ui uploads",
    "",
    "# Create Python virtual environment",
    "python3 -m venv venv",
    "source venv/bin/activate",
    "",
    "# Install dependencies",
    "pip install --upgrade pip",
    "pip install -r requirements.txt",
    "",
    "# Create configuration file",
    "cat > assets/config/stream_configuration.json << 'EOF'",
    "{",
    "  \"streams\": [",
    "    {",
    "      \"id\": \"simple_sequential\",",
    "      \"name\": \"Simple Concept Drift\",",
    "      \"description\": \"A basic stream with sudden concept drift at 60%\",",
    "      \"type\": \"pnml_drift\",",
    "      \"is_testing\": true,",
    "      \"pnml_log_a\": \"data/model_one.pnml\",",
    "      \"pnml_log_b\": \"data/model_two.pnml\",",
    "      \"drift_config\": {",
    "        \"drift_type\": \"sudden\",",
    "        \"drift_begin_percentage\": 0.6,",
    "        \"drift_end_percentage\": 0.6,",
    "        \"event_level_drift\": false,",
    "        \"num_cases_a\": 300,",
    "        \"num_cases_b\": 200",
    "      }",
    "    }",
    "  ]",
    "}",
    "EOF",
    "",
    "# Set permissions",
    "chmod 755 uploads",
    "chmod 644 assets/config/stream_configuration.json",
    "",
    "echo \"✅ Setup complete!\"",
    "echo \"\"",
    "echo \"To start the platform:\"",
    "echo \"1. Activate virtual environment: source venv/bin/activate\"",
    "echo \"2. Run the application: python app.py\"",
    "echo \"3. Open browser to: http://localhost:8050\"",
    "echo \"\"",
    "echo \"📚 Check the documentation tab in the platform for usage instructions.\"",
  ],
  
  "health_check.py": [
    "#!/usr/bin/env python3",
    "\"\"\"",
    "Health check script for the Streaming Process Mining Challenge platform.",
    "\"\"\"",
    "",
    "import requests",
    "import sys",
    "import json",
    "from datetime import datetime",
    "",
    "def check_health():",
    "    \"\"\"Check if the application is healthy.\"\"\"",
    "    try:",
    "        # Check main application",
    "        response = requests.get('http://localhost:8050/', timeout=10)",
    "        if response.status_code != 200:",
    "            print(f\"❌ Application returned status {response.status_code}\")",
    "            return False",
    "        ",
    "        # Check if database is accessible",
    "        try:",
    "            from leaderboard_system import SubmissionManager",
    "            submission_manager = SubmissionManager('uploads')",
    "            stats = submission_manager.leaderboard_manager.get_leaderboard_stats()",
    "            print(f\"✅ Database accessible - {stats['total_submissions']} submissions\")",
    "        except Exception as e:",
    "            print(f\"⚠️ Database check failed: {e}\")",
    "            return False",
    "        ",
    "        print(f\"✅ Application healthy at {datetime.now()}\")",
    "        return True",
    "        ",
    "    except requests.exceptions.RequestException as e:",
    "        print(f\"❌ Health check failed: {e}\")",
    "        return False",
    "",
    "if __name__ == '__main__':",
    "    if check_health():",
    "        sys.exit(0)",
    "    else:",
    "        sys.exit(1)"
  ],
  
  "run_tests.py": [
    "#!/usr/bin/env python3",
    "\"\"\"",
    "Test suite for the Streaming Process Mining Challenge platform.",
    "\"\"\"",
    "",
    "import unittest",
    "import tempfile",
    "import os",
    "import json",
    "from datetime import datetime",
    "",
    "# Import platform components",
    "from leaderboard_system import SubmissionManager, SubmissionEntry",
    "from file_upload_utils import AlgorithmUploadManager, UploadValidator",
    "",
    "class TestSubmissionSystem(unittest.TestCase):",
    "    \"\"\"Test submission and evaluation system.\"\"\"",
    "    ",
    "    def setUp(self):",
    "        self.temp_dir = tempfile.mkdtemp()",
    "        self.submission_manager = SubmissionManager(self.temp_dir)",
    "    ",
    "    def test_submission_creation(self):",
    "        \"\"\"Test creating a new submission.\"\"\"",
    "        submission_id = self.submission_manager.submit_algorithm(",
    "            team_name='Test Team',",
    "            email='test@example.com',",
    "            algorithm_name='Test Algorithm',",
    "            description='Test description',",
    "            file_path='/tmp/test.py',",
    "            libraries=['numpy', 'pandas']",
    "        )",
    "        ",
    "        self.assertIsNotNone(submission_id)",
    "        submission = self.submission_manager.database.get_submission(submission_id)",
    "        self.assertEqual(submission.team_name, 'Test Team')",
    "",
    "class TestFileUpload(unittest.TestCase):",
    "    \"\"\"Test file upload functionality.\"\"\"",
    "    ",
    "    def setUp(self):",
    "        self.temp_dir = tempfile.mkdtemp()",
    "        self.upload_manager = AlgorithmUploadManager(self.temp_dir)",
    "        self.validator = UploadValidator()",
    "    ",
    "    def test_file_validation(self):",
    "        \"\"\"Test file validation.\"\"\"",
    "        # Test valid Python file",
    "        valid, errors, warnings = self.validator.validate_file(",
    "            'data:text/plain;base64,cHJpbnQoImhlbGxvIik=',  # print(\"hello\")",
    "            'test.py'",
    "        )",
    "        self.assertTrue(valid)",
    "        self.assertEqual(len(errors), 0)",
    "        ",
    "        # Test invalid file type",
    "        valid, errors, warnings = self.validator.validate_file(",
    "            'data:text/plain;base64,dGVzdA==',",
    "            'test.txt'",
    "        )",
    "        self.assertFalse(valid)",
    "        self.assertGreater(len(errors), 0)",
    "",
    "if __name__ == '__main__':",
    "    unittest.main()"
  ]
}